{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6f2ba3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "def copy_folder(source: str, destination: str):\n",
    "    source_path = Path(source)\n",
    "    destination_path = Path(destination)\n",
    "\n",
    "    try:\n",
    "        shutil.copytree(src=source_path, dst=destination_path, dirs_exist_ok=True)\n",
    "        print(f\"✅ Folder copied from '{source}' to '{destination}'\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Failed to copy folder: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f148f441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Folder copied from 'C:\\Users\\wasim\\.cache\\kagglehub\\datasets\\sumn2u\\garbage-classification-v2\\versions\\8' to 'D:\\project\\garbage_classification\\models'\n"
     ]
    }
   ],
   "source": [
    "source = \"C:\\\\Users\\\\wasim\\\\.cache\\\\kagglehub\\\\datasets\\\\sumn2u\\\\garbage-classification-v2\\\\versions\\\\8\"\n",
    "destination = \"D:\\\\project\\\\garbage_classification\\\\models\"\n",
    "copy_folder(source, destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d77aee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "destination_path = Path(Path.cwd().parent.parent / \"raw_data\")\n",
    "os.makedirs(destination_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "802068f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total files in : 19762\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "destination_path = r\"D:\\\\project\\\\garbage_classification\\\\garbage-dataset\"\n",
    "total_files = 0\n",
    "for root, dirs, files in os.walk(destination_path):\n",
    "    total_files += len(files)\n",
    "print(f\"Total files in : {total_files}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ede68e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:2: SyntaxWarning: invalid escape sequence '\\c'\n",
      "<>:2: SyntaxWarning: invalid escape sequence '\\c'\n",
      "C:\\Users\\wasim\\AppData\\Local\\Temp\\ipykernel_15240\\2768455314.py:2: SyntaxWarning: invalid escape sequence '\\c'\n",
      "  config_file = \"training\\configs\\config.yaml\"\n",
      "C:\\Users\\wasim\\AppData\\Local\\Temp\\ipykernel_15240\\2768455314.py:2: SyntaxWarning: invalid escape sequence '\\c'\n",
      "  config_file = \"training\\configs\\config.yaml\"\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'training\\\\configs\\\\config.yaml'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01myaml\u001b[39;00m\n\u001b[32m      2\u001b[39m config_file = \u001b[33m\"\u001b[39m\u001b[33mtraining\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mconfigs\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mconfig.yaml\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mconfig_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mw\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m      4\u001b[39m     yaml.dump(\u001b[33m\"\u001b[39m\u001b[33moutput_path: \u001b[39m\u001b[33m\"\u001b[39m + \u001b[38;5;28mstr\u001b[39m(destination_path), f)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\project\\garbage_classification\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:327\u001b[39m, in \u001b[36m_modified_open\u001b[39m\u001b[34m(file, *args, **kwargs)\u001b[39m\n\u001b[32m    320\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m}:\n\u001b[32m    321\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    322\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mIPython won\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m by default \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    323\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    324\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33myou can use builtins\u001b[39m\u001b[33m'\u001b[39m\u001b[33m open.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    325\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m327\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'training\\\\configs\\\\config.yaml'"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "config_file = r\"training\\\\configs\\\\config.yaml\"\n",
    "with open(config_file, 'w') as f:\n",
    "    yaml.dump(\"output_path: \" + str(destination_path), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c550317",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '__file__' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msys\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpathlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m sys.path[\u001b[32m0\u001b[39m]=\u001b[38;5;28mstr\u001b[39m(Path(\u001b[34;43m__file__\u001b[39;49m).resolve().parent.parent)\n\u001b[32m      5\u001b[39m os.makedirs(\u001b[33m\"\u001b[39m\u001b[33mtraining\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[33martifacts\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[33mtemp\u001b[39m\u001b[33m\"\u001b[39m,exist_ok=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[31mNameError\u001b[39m: name '__file__' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path[0]=str(Path(__file__).resolve().parent.parent)\n",
    "os.makedirs(\"training\\\\artifacts\\\\temp\",exist_ok=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff120b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12bd816",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6338b5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import yaml\n",
    "\n",
    "def merge_yaml(file_path: str | Path, new_data: dict | str) -> None:\n",
    "    \"\"\"\n",
    "    Add or update keys in an existing YAML file.\n",
    "\n",
    "    • Keeps every key that’s already there.\n",
    "    • Over‑writes values only for keys that also exist in `new_data`.\n",
    "    • Appends brand‑new keys at the end.\n",
    "    \"\"\"\n",
    "    file_path = Path(file_path)\n",
    "\n",
    "    if new_data is str:\n",
    "        new_data = \n",
    "\n",
    "    # 1️⃣  Read whatever is already in the file (may be empty / missing)\n",
    "    current: dict = {}\n",
    "    if file_path.exists():\n",
    "        with file_path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "            current = yaml.safe_load(f) or {}\n",
    "\n",
    "    # 2️⃣  Merge: overwrite duplicates, keep the rest\n",
    "    current.update(new_data)          # one‑level deep merge\n",
    "    # For a deep merge, see the note below.\n",
    "\n",
    "    # 3️⃣  Write *once* in 'w' mode\n",
    "    with file_path.open(\"w\", encoding=\"utf-8\") as f:\n",
    "        yaml.safe_dump(\n",
    "            current,\n",
    "            f,\n",
    "            default_flow_style=False,   # nice block style\n",
    "            sort_keys=False             # keep key order as we merged\n",
    "        )\n",
    "\n",
    "# ----------  Example usage  ----------\n",
    "merge_yaml(\n",
    "    \"config.yaml\",\n",
    "    {\"output_path\": \"D:/project/garbage_classification/output\"}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab20cc8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def str_to_dict(s: None) -> dict:\n",
    "    \"\"\"\n",
    "    Convert a string representation of a dictionary to an actual dictionary.\n",
    "    \"\"\"\n",
    "    \n",
    "    return eval(s)  # Use with caution, eval can execute arbitrary code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee7cef4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sjfdl' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m dfjsk = \u001b[33m'\u001b[39m\u001b[33msjfdl\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mstr_to_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdfjsk\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 6\u001b[39m, in \u001b[36mstr_to_dict\u001b[39m\u001b[34m(s)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mstr_to_dict\u001b[39m(s: \u001b[38;5;28mstr\u001b[39m) -> \u001b[38;5;28mdict\u001b[39m:\n\u001b[32m      2\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[33;03m    Convert a string representation of a dictionary to an actual dictionary.\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43meval\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<string>:1\u001b[39m\n",
      "\u001b[31mNameError\u001b[39m: name 'sjfdl' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3af1d7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_dictionary(value, key_name=\"{value}\"):\n",
    "    \"\"\"\n",
    "    Converts an int, str, or float into a dictionary.\n",
    "\n",
    "    Args:\n",
    "        value: The int, str, or float to be converted.\n",
    "        key_name (str): The key to be used in the dictionary. Defaults to \"value\".\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the input value.\n",
    "    \"\"\"\n",
    "    if isinstance(value, (int, str, float)):\n",
    "        return {key_name: value}\n",
    "    else:\n",
    "        raise TypeError(\"Input must be an int, str, or float.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec75211c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'{value}': 5}\n"
     ]
    }
   ],
   "source": [
    "d = 5\n",
    "converted_dict = convert_to_dictionary(d)\n",
    "print(converted_dict)  # Output: {'value': 5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a8f2e1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Integer converted to dictionary: {'{value}': 123}\n",
      "String converted to dictionary: {'message': 'hello'}\n",
      "Float converted to dictionary: {'{value}': 3.14}\n",
      "Error converting list: Input must be an int, str, or float.\n"
     ]
    }
   ],
   "source": [
    "# Convert an integer\n",
    "int_dict = convert_to_dictionary(123)\n",
    "print(f\"Integer converted to dictionary: {int_dict}\")\n",
    "\n",
    "# Convert a string with a custom key\n",
    "str_dict = convert_to_dictionary(\"hello\", \"message\")\n",
    "print(f\"String converted to dictionary: {str_dict}\")\n",
    "\n",
    "# Convert a float\n",
    "float_dict = convert_to_dictionary(3.14)\n",
    "print(f\"Float converted to dictionary: {float_dict}\")\n",
    "\n",
    "# Attempt to convert an unsupported type (will raise an error)\n",
    "try:\n",
    "    list_dict = convert_to_dictionary([1, 2, 3])\n",
    "except TypeError as e:\n",
    "    print(f\"Error converting list: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9571a07a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'t'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_file = r\"training\\\\data_ingestion\\\\config.yaml\"\n",
    "config_file[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6408009",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "DataIngestor.__init__() missing 1 required positional argument: 'config_file'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mingest_data\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DataIngestor\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconfig_reader\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ConfigReader\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m loader = \u001b[43mDataIngestor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m train_loader, test_loader, val_loader = loader.get_dataloaders()\n\u001b[32m     10\u001b[39m \u001b[38;5;28mprint\u001b[39m(train_loader)\n",
      "\u001b[31mTypeError\u001b[39m: DataIngestor.__init__() missing 1 required positional argument: 'config_file'"
     ]
    }
   ],
   "source": [
    "# Add the path to import the .py file if not in same folder\n",
    "import sys\n",
    "sys.path.append(\"../data_processing\")  # relative path to prepare_data.py\n",
    "config_file = r\"training\\\\data_ingestion\\\\config.yaml\"\n",
    "from ingest_data import DataIngestor\n",
    "from utils.config_reader import ConfigReader\n",
    "\n",
    "loader = DataIngestor()\n",
    "train_loader, test_loader, val_loader = loader.get_dataloaders()\n",
    "print(train_loader)\n",
    "\n",
    "# # ✅ Now visualize a sample\n",
    "# import matplotlib.pyplot as plt\n",
    "# import torchvision.transforms.functional as F\n",
    "\n",
    "# images, labels = next(iter(train_loader))\n",
    "# img = F.to_pil_image(images[0])\n",
    "# plt.imshow(img)\n",
    "# plt.title(f\"Label: {labels[0].item()}\")\n",
    "# plt.axis(\"off\")\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8dfacf4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
